#!/usr/bin/env python3
"""
Enhanced Tana Obsidian Vault Generator - Convert Tana JSON exports to Obsidian vault
Excludes system content and uses our proven import logic with diary consolidation.
"""

import sys
import json
import argparse
from pathlib import Path
from typing import Dict, Any, List, Tuple, Set
import re
from datetime import datetime

# Add parent directory to path for shared libraries
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from lib import TanaImporter, Colors


class EnhancedObsidianVaultGenerator:
    """Generate Obsidian vault from Tana JSON exports using our proven import logic"""

    def __init__(self, files_dir: Path = None):
        """Initialize with custom files directory"""
        self.tana_importer = TanaImporter(files_dir)
        self.tana_io = self.tana_importer.tana_io
        self.vault_dir = self.tana_io.export_dir / "obsidian"
        self.node_index: Dict[str, Dict[str, Any]] = {}
        self.user_supertags: Dict[str, str] = {}  # name -> node_id

        # Smart folder mapping for user content
        self.supertag_folder_mapping = {
            # Time-based content (consolidated into diary)
            'day': 'diary',
            'week': 'diary',
            'month': 'diary',
            'quarter': 'diary',
            'year': 'diary',

            # Project & work
            'project': 'projects',
            'goal': 'goals',
            'task': 'tasks',

            # Content & notes
            'atomic note': 'notes',
            'spark note': 'notes',
            'note': 'notes',
            'document': 'documents',

            # People & planning
            'contact': 'contacts',
            'person': 'contacts',
            'meeting': 'meetings',
            'journal': 'journal',  # Personal journaling (distinct from time diary)

            # Thinking & strategy
            'vision': 'vision',
            'topic': 'topics',
            'idea': 'ideas',
            'area': 'areas'
        }

    def is_user_content(self, node: Dict[str, Any]) -> bool:
        """Filter to only export meaningful user content"""
        node_id = node.get('id', '')
        props = node.get('props', {})

        # Exclude system nodes
        if node_id.startswith('SYS_'):
            return False

        # Exclude system structures
        if props.get('_docType') in ['tagDef', 'metanode']:
            return False

        # Exclude empty/placeholder content
        name = props.get('name', '').strip()
        if not name or name.lower() in ['no name', 'untitled', '']:
            return False

        return True

    def create_vault_structure(self):
        """Create the enhanced Obsidian vault structure"""
        # Create main vault directory
        self.vault_dir.mkdir(parents=True, exist_ok=True)

        # Create .obsidian directory with enhanced configuration
        obsidian_config_dir = self.vault_dir / ".obsidian"
        obsidian_config_dir.mkdir(exist_ok=True)

        # Create enhanced Obsidian configuration
        self.create_obsidian_config()

        # Create smart directory structure
        dirs_to_create = [
            'diary', 'projects', 'goals', 'tasks', 'notes', 'documents',
            'contacts', 'meetings', 'journal', 'vision', 'topics', 'areas', 'library'
        ]

        for dir_name in dirs_to_create:
            (self.vault_dir / dir_name).mkdir(exist_ok=True)

        Colors.success(f"Created enhanced Obsidian vault structure at: {self.vault_dir}")

    def create_obsidian_config(self):
        """Create enhanced Obsidian configuration files"""
        # Enhanced app.json optimized for Tana content
        app_config = {
            "legacyEditor": False,
            "promptDelete": False,
            "newFileLocation": "folder",
            "newFileFolderPath": "Inbox",
            "attachmentFolderPath": "Attachments",
            "alwaysUpdateLinks": True,
            "useMarkdownLinks": True,
            "newLinkFormat": "shortest",
            "strictLineBreaks": True,
            "foldHeading": True,
            "foldIndent": True,
            "showLineNumber": True,
            "rightToLeft": False,
            "autoConvertHtml": True,
            "livePreview": True
        }

        config_file = self.vault_dir / ".obsidian" / "app.json"
        with open(config_file, 'w') as f:
            json.dump(app_config, f, indent=2)

        # Enhanced community plugins for Tana workflow
        plugins_dir = self.vault_dir / ".obsidian" / "plugins"
        plugins_dir.mkdir(exist_ok=True)

        community_plugins = {
            "plugins": [
                "dataview",
                "calendar",
                "cm-editor-syntax-highlight-obsidian",
                "obsidian-tasks-plugin",
                "tag-wrangler",
                "quick-switcher-plus"
            ]
        }

        plugins_file = plugins_dir / "community-plugins.json"
        with open(plugins_file, 'w') as f:
            json.dump(community_plugins, f, indent=2)

        # Dataview configuration for time-based content
        dataview_config = {
            "dataview": {
                "query": {
                    "inlineQueryPrefix": "$",
                    "inlineJsQueryPrefix": "$$"
                },
                "table": {
                    "pageSize": 20
                }
            }
        }

        data_view_file = plugins_dir / "dataview.json"
        with open(data_view_file, 'w') as f:
            json.dump(dataview_config, f, indent=2)

    def discover_all_supertags(self, data: Dict[str, Any]) -> Dict[str, str]:
        """Discover all user-defined supertags (not just keytags)"""
        Colors.info("ðŸ” Discovering all user supertags...")

        docs = data.get('docs', data.get('nodes', []))
        user_supertags = {}

        # Find all supertag definitions
        for doc in docs:
            props = doc.get('props', {})
            if props.get('_docType') == 'tagDef':
                name = props.get('name', '').lower()
                supertag_id = doc.get('id', '')

                # Exclude system supertags
                if name and supertag_id and not supertag_id.startswith('SYS_'):
                    user_supertags[name] = supertag_id

        Colors.success(f"Found {len(user_supertags)} user supertags")
        return user_supertags

    def build_metanode_mappings(self, data: Dict[str, Any]) -> Dict[str, str]:
        """Build metanode to supertag mappings using our proven algorithm"""
        docs = data.get('docs', data.get('nodes', []))
        doc_lookup = {doc.get('id'): doc for doc in docs}

        # Build target supertag ID set
        target_supertag_ids = set(self.user_supertags.values())

        meta_node_to_supertag = {}

        Colors.info("ðŸ—ï¸ Building metanode mappings...")

        # Trace metanode hierarchy efficiently
        for doc in docs:
            if not doc.get('children'):
                continue

            doc_id = doc.get('id')
            children = doc.get('children', [])

            # Check if this document has a structure we care about
            for child_id in children:
                child_doc = doc_lookup.get(child_id)
                if not child_doc or not child_doc.get('children'):
                    continue

                child_children = child_doc.get('children', [])
                for grandchild_id in child_children:
                    if grandchild_id in target_supertag_ids:
                        # Found mapping!
                        for supertag_name, supertag_id in self.user_supertags.items():
                            if grandchild_id == supertag_id:
                                meta_node_to_supertag[doc_id] = supertag_name
                                break

        Colors.success(f"Built {len(meta_node_to_supertag)} metanode mappings")
        return meta_node_to_supertag

    def extract_user_nodes(self, data: Dict[str, Any]) -> Dict[str, List[Dict[str, Any]]]:
        """Extract user nodes organized by supertag"""
        Colors.info("ðŸ“Š Extracting user nodes...")

        docs = data.get('docs', data.get('nodes', []))
        doc_lookup = {doc.get('id'): doc for doc in docs}
        meta_node_to_supertag = self.build_metanode_mappings(data)

        nodes_by_supertag = {}

        # Initialize empty lists for all known supertags
        for supertag_name in self.user_supertags.keys():
            nodes_by_supertag[supertag_name] = []

        # Process nodes and assign to supertags
        for doc in docs:
            if not self.is_user_content(doc):
                continue

            props = doc.get('props', {})
            meta_node_id = props.get('_metaNodeId')

            # Check if this node has any user supertag
            if meta_node_id and meta_node_id in meta_node_to_supertag:
                supertag_name = meta_node_to_supertag[meta_node_id]

                node_info = {
                    'name': props.get('name', 'Untitled'),
                    'node_id': doc.get('id', 'unknown'),
                    'description': props.get('description', ''),
                    'created': props.get('created'),
                    'children': doc.get('children', []),
                    'props': props
                }

                nodes_by_supertag[supertag_name].append(node_info)

        # Count total nodes processed
        total_nodes = sum(len(nodes) for nodes in nodes_by_supertag.values())
        Colors.success(f"Extracted {total_nodes} user nodes across {len(self.user_supertags)} supertags")

        return nodes_by_supertag

    def get_folder_for_supertag(self, supertag_name: str) -> str:
        """Get the target folder for a supertag"""
        return self.supertag_folder_mapping.get(supertag_name, 'library')

    def format_time_based_filename(self, node_info: Dict[str, Any], supertag_name: str) -> str:
        """Create proper filename for time-based content"""
        node_name = node_info.get('name', '')
        created = node_info.get('created')

        if not created:
            return f"{node_name}.md"

        # Parse creation date
        if isinstance(created, str):
            try:
                date_obj = datetime.fromisoformat(created.replace('Z', '+00:00'))
            except:
                date_obj = datetime.fromtimestamp(int(created)/1000) if created.isdigit() else datetime.now()
        else:
            date_obj = datetime.fromtimestamp(created/1000)

        # Format based on supertag type
        if supertag_name == 'day':
            return date_obj.strftime("%Y-%m-%d.md")
        elif supertag_name == 'week':
            week_num = date_obj.isocalendar()[1]
            return f"{date_obj.year}-W{week_num:02d}.md"
        elif supertag_name == 'month':
            return f"{date_obj.year}-{date_obj.strftime('%B')}.md"
        elif supertag_name == 'year':
            return f"{date_obj.year}.md"
        else:
            return self.sanitize_filename(f"{node_name}.md")

    def sanitize_filename(self, filename: str) -> str:
        """Sanitize a node name for use as a filename"""
        # Remove invalid filesystem characters
        sanitized = re.sub(r'[<>:"/\\|?*]', '-', filename)
        sanitized = re.sub(r'[^\w\s\-().]', '', sanitized)
        sanitized = re.sub(r'\s+', '-', sanitized).strip('-')

        # Limit length
        max_length = 80
        if len(sanitized) > max_length and sanitized.endswith('.md'):
            sanitized = sanitized[:max_length-3] + '.md'
        elif len(sanitized) > max_length:
            sanitized = sanitized[:max_length-3] + '...'

        return sanitized or 'untitled.md'

    def create_obsidian_node_file(self, node_info: Dict[str, Any], supertag_name: str, folder_path: Path, doc_lookup: Dict[str, Any]) -> str:
        """Create an Obsidian markdown file for a node with YAML frontmatter"""
        node_name = node_info.get('name', 'Untitled')
        node_id = node_info.get('node_id', 'unknown')

        # Determine filename
        if supertag_name in ['day', 'week', 'month', 'year']:
            filename = self.format_time_based_filename(node_info, supertag_name)
        else:
            filename = f"{node_id}.md"  # Use node ID for consistency

        file_path = folder_path / filename

        # Generate YAML frontmatter
        frontmatter = []
        frontmatter.append("---")
        frontmatter.append(f"created: {self.format_created_date(node_info.get('created'))}")
        frontmatter.append(f"node_id: {node_id}")
        frontmatter.append(f"supertags:")
        frontmatter.append(f"  - {supertag_name}")

        # Add additional tags from folder
        folder_name = self.get_folder_for_supertag(supertag_name)
        if folder_name != 'library':
            frontmatter.append(f"tags:")
            frontmatter.append(f"  - {supertag_name}")
            frontmatter.append(f"  - {folder_name}")

        frontmatter.append("---")

        # Generate content
        content_lines = []

        # Add frontmatter
        content_lines.extend(frontmatter)
        content_lines.append("")

        # Title
        content_lines.append(f"# {node_name}")
        content_lines.append("")

        # Supertags section
        content_lines.append("## ðŸ·ï¸ Supertags")
        content_lines.append(f"- **{supertag_name.title()}**")
        content_lines.append("")

        # Children section using our proven logic
        children = node_info.get('children', [])
        if children:
            content_lines.append("## ðŸ“‹ Children")
            content_lines.append("")

            for child_id in children:
                child_content = self.get_child_content(child_id, node_id, doc_lookup)
                if child_content:
                    content_lines.append(child_content)
            content_lines.append("")

        # Node metadata
        content_lines.append("## ðŸ“ Node Details")
        content_lines.append(f"**Node ID:** `{node_id}`")

        created = node_info.get('created')
        if created:
            if isinstance(created, str):
                content_lines.append(f"**Created:** {created}")
            else:
                created_date = datetime.fromtimestamp(created/1000).strftime('%Y-%m-%d %H:%M:%S')
                content_lines.append(f"**Created:** {created_date}")

        description = node_info.get('description', '')
        if description and description.strip():
            content_lines.append(f"**Description:** {description}")

        content_lines.append("")
        content_lines.append("---")
        content_lines.append(f"*Created from Tana export - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

        # Write file
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(content_lines))

        return filename

    def get_child_content(self, child_id: str, parent_node_id: str, doc_lookup: Dict[str, Any] = None) -> str:
        """Get child content preserving formatting, returning markdown (reused from our working logic)"""
        if not doc_lookup:
            return f"- [[{child_id}.md]]"

        child_doc = doc_lookup.get(child_id)
        if not child_doc:
            return f"- [[{child_id}.md]]"

        props = child_doc.get('props', {})

        # If this is a regular node with a name, create a link
        child_name = props.get('name')
        if child_name and child_name.strip():
            return f"- [[{child_id}.md|{child_name}]]"

        # If this is content-only, use the content as-is
        content_fields = ['description', 'content', 'text']
        for field in content_fields:
            if field in props and props[field]:
                content = props[field]
                if isinstance(content, str) and content.strip():
                    return f"- {content}"

        # Look for fields that could contain rich text
        for key, value in props.items():
            if key not in ['created', '_ownerId', '_flags', '_metaNodeId', '_docType', '_sourceId']:
                if isinstance(value, str) and value.strip() and len(value) > 20:
                    return f"- {value}"

        return f"- [[{child_id}.md|Child Node]]"

    def format_created_date(self, created) -> str:
        """Format created date for YAML frontmatter"""
        if not created:
            return ""

        if isinstance(created, str):
            try:
                date_obj = datetime.fromisoformat(created.replace('Z', '+00:00'))
                return date_obj.strftime('%Y-%m-%d %H:%M:%S')
            except:
                try:
                    date_obj = datetime.fromtimestamp(int(created)/1000)
                    return date_obj.strftime('%Y-%m-%d %H:%M:%S')
                except:
                    return created
        else:
            date_obj = datetime.fromtimestamp(created/1000)
            return date_obj.strftime('%Y-%m-%d %H:%M:%S')

    def create_index_files(self, nodes_by_supertag: Dict[str, List[Dict[str, Any]]], import_file: Path):
        """Create comprehensive index files for navigation"""
        Colors.info("ðŸ“ Creating index files...")

        # Create main home page
        home_content = [
            "# ðŸ  Tana Vault",
            "",
            f"*Imported from {import_file.name} on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*",
            "",
            "## ðŸ“Š Overview",
            "",
            f"- **Total Nodes:** {sum(len(nodes) for nodes in nodes_by_supertag.values())}",
            f"- **Supertags Found:** {len([s for s in nodes_by_supertag.values() if s])}",
            "",
            "## ðŸ“ Content Areas",
            ""
        ]

        # Group by folder for cleaner organization
        folder_content = {}

        for supertag_name, nodes in nodes_by_supertag.items():
            if not nodes:
                continue

            folder = self.get_folder_for_supertag(supertag_name)
            if folder not in folder_content:
                folder_content[folder] = []

            # Sort nodes by creation date or name
            sorted_nodes = sorted(nodes, key=lambda x: (
                x.get('created', 0) if isinstance(x.get('created'), (int, float)) else 0,
                x.get('name', '').lower()
            ), reverse=True)

            folder_content[folder].append({
                'supertag': supertag_name,
                'count': len(nodes),
                'nodes': sorted_nodes[:5]  # Show first 5 as examples
            })

        # Add folder sections to home page
        for folder, supertag_info in sorted(folder_content.items()):
            if folder == 'diary':
                home_content.extend([
                    f"### ðŸ“… {folder.title()}",
                    "All your time-based content organized chronologically:",
                    ""
                ])
            elif folder == 'projects':
                home_content.extend([
                    f"### ðŸš€ {folder.title()}",
                    "Your active projects and initiatives:",
                    ""
                ])
            else:
                home_content.extend([
                    f"### ðŸ“š {folder.title()}",
                    ""
                ])

            for info in supertag_info:
                home_content.append(f"**{info['supertag'].title()}** ({info['count']} items)")

                # Add recent examples
                for node in info['nodes']:
                    node_name = node.get('name', 'Untitled')
                    created = node.get('created')

                    # Determine filename
                    if info['supertag'] in ['day', 'week', 'month', 'year']:
                        filename = self.format_time_based_filename(node, info['supertag'])
                    else:
                        filename = f"{node.get('node_id')}.md"

                    if created:
                        if isinstance(created, (int, float)):
                            date_str = datetime.fromtimestamp(created/1000).strftime('%Y-%m-%d')
                            home_content.append(f"  - [[{filename}|{node_name}]] ({date_str})")
                        else:
                            home_content.append(f"  - [[{filename}|{node_name}]]")
                    else:
                        home_content.append(f"  - [[{filename}|{node_name}]]")
                home_content.append("")

            home_content.append("")

        # Add navigation links
        home_content.extend([
            "## ðŸ”— Quick Navigation",
            "",
            "- **ðŸ“… Diary** - Browse chronologically through days, weeks, months, years",
            "- **ðŸš€ Projects** - Track your active projects and initiatives",
            "- **âœ… Tasks** - Manage your action items and todos",
            "- **ðŸ“ Notes** - Access all your notes and thoughts",
            "- **ðŸ‘¥ Contacts** - Your people and network",
            "- **ðŸŽ¯ Goals** - Track objectives and aspirations",
            "- **ðŸ”® Vision** - Your long-term plans and strategy",
            "",
            "---",
            "*Vault generated with enhanced TanaChat Obsidian exporter*"
        ])

        # Write home file
        home_file = self.vault_dir / "ðŸ  Home.md"
        with open(home_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(home_content))

        # Create diary-specific index
        if 'day' in nodes_by_supertag or 'week' in nodes_by_supertag or 'month' in nodes_by_supertag or 'year' in nodes_by_supertag:
            self.create_diary_index(nodes_by_supertag)

    def create_diary_index(self, nodes_by_supertag: Dict[str, List[Dict[str, Any]]]):
        """Create a special index for diary content"""
        diary_content = [
            "# ðŸ“… Diary & Time-Based Content",
            "",
            "Your chronological journey through days, weeks, months, and years.",
            "",
            "## ðŸ—“ï¸ Recent Time Entries",
            ""
        ]

        # Collect and sort all time-based content
        all_time_nodes = []

        for time_supertag in ['day', 'week', 'month', 'year']:
            if time_supertag in nodes_by_supertag:
                for node in nodes_by_supertag[time_supertag]:
                    node['supertag'] = time_supertag
                    all_time_nodes.append(node)

        # Sort by creation date
        all_time_nodes.sort(key=lambda x: x.get('created', 0), reverse=True)

        # Add recent entries
        for node in all_time_nodes[:20]:
            node_name = node.get('name', 'Untitled')
            supertag = node['supertag']
            created = node.get('created')

            filename = self.format_time_based_filename(node, supertag)

            if isinstance(created, (int, float)):
                date_str = datetime.fromtimestamp(created/1000).strftime('%Y-%m-%d')
                diary_content.append(f"- [[{filename}|{node_name}]] ({date_str})")
            else:
                diary_content.append(f"- [[{filename}|{node_name}]]")

        diary_content.extend([
            "",
            "## ðŸ“ˆ Browse by Time Period",
            "",
            "### ðŸ“… Daily Entries",
            f"- [[ðŸ“… All Days|View all {len(nodes_by_supertag.get('day', []))} daily entries]]",
            "",
            "### ðŸ“† Weekly Reviews",
            f"- [[ðŸ“† All Weeks|View all {len(nodes_by_supertag.get('week', []))} weekly reviews]]",
            "",
            "### ðŸ—“ï¸ Monthly Plans",
            f"- [[ðŸ—“ï¸ All Months|View all {len(nodes_by_supertag.get('month', []))} monthly plans]]",
            "",
            "### ðŸŒŸ Annual Goals",
            f"- [[ðŸŒŸ All Years|View all {len(nodes_by_supertag.get('year', []))} annual goals]]",
            ""
        ])

        diary_file = self.vault_dir / "diary" / "ðŸ“… Diary Index.md"
        with open(diary_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(diary_content))

    def generate_vault(self, import_file: Path) -> Dict[str, Any]:
        """Generate the complete Obsidian vault using our proven logic"""
        Colors.info(f"ðŸš€ Generating enhanced Obsidian vault from {import_file.name}")

        try:
            # Load and parse the Tana JSON
            with open(import_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # Create vault structure
            self.create_vault_structure()

            # Discover all user supertags
            self.user_supertags = self.discover_all_supertags(data)

            # Extract user nodes by supertag
            nodes_by_supertag = self.extract_user_nodes(data)

            # Create doc lookup for content processing
            docs = data.get('docs', data.get('nodes', []))
            doc_lookup = {doc.get('id'): doc for doc in docs}

            # Create individual node files
            Colors.info("ðŸ“ Creating node files...")
            files_created = 0
            folder_stats = {}

            for supertag_name, nodes in nodes_by_supertag.items():
                if not nodes:
                    continue

                folder_name = self.get_folder_for_supertag(supertag_name)
                folder_path = self.vault_dir / folder_name
                folder_stats[folder_name] = 0

                Colors.info(f"ðŸ“ Creating {len(nodes)} files in '{folder_name}' directory")

                for node_info in nodes:
                    filename = self.create_obsidian_node_file(node_info, supertag_name, folder_path, doc_lookup)
                    files_created += 1
                    folder_stats[folder_name] += 1

                Colors.success(f"âœ… Created {len(nodes)} files in '{folder_name}' directory")

            # Create comprehensive index files
            self.create_index_files(nodes_by_supertag, import_file)

            # Generate summary
            result = {
                'success': True,
                'vault_path': self.vault_dir,
                'total_nodes': sum(len(nodes) for nodes in nodes_by_supertag.values()),
                'supertags_found': len([s for s in nodes_by_supertag.values() if s]),
                'files_created': files_created,
                'folder_stats': folder_stats,
                'message': f"Successfully created enhanced Obsidian vault with {sum(len(nodes) for nodes in nodes_by_supertag.values())} user nodes"
            }

            Colors.success(f"âœ… {result['message']}")
            return result

        except Exception as e:
            error_msg = f"Failed to generate Obsidian vault: {e}"
            Colors.error(error_msg)
            return {
                'success': False,
                'error': error_msg
            }


def get_import_file():
    """Get import file from user selection"""
    # List available files
    import_files = list(Path("files/import").glob("*.json"))
    if not import_files:
        Colors.error(f"No JSON files found in files/import/")
        return None

    # Display files
    print(f"\n{Colors.CYAN}ðŸ“ Available Tana JSON files:{Colors.END}")
    for i, file_path in enumerate(import_files, 1):
        size = file_path.stat().st_size
        size_str = f"{size/1024/1024:.2f} MB" if size > 1024*1024 else f"{size/1024:.1f} KB"
        print(f"   {i}. {Colors.BOLD}{file_path.name}{Colors.END}")
        print(f"      Size: {size_str}")

    # Get user selection
    while True:
        try:
            choice = input(f"\n{Colors.YELLOW}Select file to convert (1-{len(import_files)}):{Colors.END} ")
            if choice.strip():
                choice_num = int(choice.strip())
                if 1 <= choice_num <= len(import_files):
                    return import_files[choice_num - 1]
                else:
                    Colors.warning("Invalid selection")
            else:
                Colors.warning("Please enter a number")
        except ValueError:
            Colors.warning("Please enter a valid number")
        except KeyboardInterrupt:
            Colors.info("\nOperation cancelled")
            return None


def main():
    """Main function"""
    parser = argparse.ArgumentParser(
        description="Convert Tana JSON exports to enhanced Obsidian vault (user content only)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
This enhanced tool converts Tana JSON exports into a comprehensive Obsidian vault:

1. Exports only meaningful user content (no system nodes)
2. Uses our proven metanode hierarchy detection
3. Preserves all formatting (bold, italics, links)
4. Consolidates time-based content into diary folder
5. Creates smart folder organization
6. Generates comprehensive navigation and indexes

Examples:
  tanachat-obsidian-new                      # Interactive mode
  tanachat-obsidian-new --file specific.json # Convert specific file
  tanachat-obsidian-new --files-dir /path/to/files   # Custom files directory
        """
    )

    parser.add_argument("-f", "--file", help="Specific JSON file to convert (skip selection)")
    parser.add_argument("--files-dir", help="Custom files directory (default: ./files)")

    args = parser.parse_args()

    # Initialize generator
    files_dir = Path(args.files_dir) if args.files_dir else None
    generator = EnhancedObsidianVaultGenerator(files_dir)

    print(f"{Colors.CYAN}ðŸš€ Enhanced Tana Obsidian Vault Generator{Colors.END}")
    print(f"Files directory: {generator.tana_io.import_dir}")
    print(f"Vault directory: {generator.vault_dir}")

    # Get import file
    if args.file:
        import_file = Path(args.file)
        if not import_file.exists():
            Colors.error(f"File not found: {args.file}")
            sys.exit(1)
    else:
        import_file = get_import_file()

    if not import_file:
        Colors.error("No valid JSON file selected")
        sys.exit(1)

    print(f"\n{Colors.CYAN}ðŸ“¥ Selected file: {Colors.BOLD}{import_file.name}{Colors.END}")

    # Generate the vault
    result = generator.generate_vault(import_file)

    if result['success']:
        print(f"\n{Colors.GREEN}âœ… Enhanced vault generation completed successfully!{Colors.END}")
        print(f"\n{Colors.BLUE}ðŸ“Š Summary:{Colors.END}")
        print(f"  Source file: {import_file.name}")
        print(f"  Vault path: {result['vault_path']}")
        print(f"  User nodes: {result['total_nodes']}")
        print(f"  Supertags: {result['supertags_found']}")
        print(f"  Files created: {result['files_created']}")

        print(f"\n{Colors.BLUE}ðŸ“ Folder breakdown:{Colors.END}")
        for folder, count in result['folder_stats'].items():
            print(f"  ðŸ“‚ {folder}/: {count} files")

        print(f"\n{Colors.BLUE}ðŸ”— Next steps:{Colors.END}")
        print(f"  1. Open {result['vault_path']} in Obsidian")
        print(f"  2. Start with ðŸ  Home.md for navigation")
        print(f"  3. Browse ðŸ“… Diary/ for chronological content")
        print(f"  4. Explore project, task, and note folders")
        print(f"  5. Use Obsidian's search and graph view")
    else:
        Colors.error("Vault generation failed")
        sys.exit(1)


if __name__ == "__main__":
    main()